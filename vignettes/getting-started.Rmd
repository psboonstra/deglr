---
title: "Getting started"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Getting started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(digits = 4)
```

```{r setup}
#library(deglr)
devtools::load_all()
library(glmnet)
library(survival)
library(tidyverse)
library(knitr)
library(glue)
```

## Setup

Here we set the number of observations from the target and external populations
as well as the number of predictors. We will draw a large number of observations
from each but then sub-sample from these large numbers to demonstrate some problems
with the current algorithm that arise when the ratio of sample sizes is large
in favor of the external population. 

```{r}
n_tar = 5e3; # size of target population
n_ext = 5e3; # size of external population
d = 25; # number of predictors
set.seed(1);
```

### Distribution of predictors 

We will generate the predictors from multivariate normal distributions with mean
zero and covariance matrices sampled from a Wishart distribution. You can increase
the `wishart_precision` to force the diagonals closer to 1, and you can change
`correlation` to increase or decrease the correlation between predictors. You 
can change `scale_target` to modify the relative values of covariance matrices
between the populations; a value of 1 means they share the same covariance matrix;
a value less than 1 means that the target population has less variability. 

```{r}
wishart_precision = 10; 
correlation = 0.15
scale_target = 0.45;
cov_tar = rWishart(1, df = d * wishart_precision, (correlation + diag(1 - correlation, d)) / (d * wishart_precision))[, , 1]
cov_ext <- cov_tar * scale_target
```

Now generate the predictors:

```{r}
xtar <- matrix(rnorm(n_tar * d), ncol = d) %*%  chol(cov_tar)
xext <- matrix(rnorm(n_ext * d), ncol = d) %*%  chol(cov_ext)
```

### Construct linear predictors

Now calculate the linear predictors ($X_i^\top \beta$ or
$X_i^\top(\beta+\gamma)$). The true value of $\beta$ is $\beta=0$ (without loss of
generality because we're not shrinking $\beta$ toward zero), and the true value
of $\gamma$ is the evenly spaced sequence of numbers from $-c$ to $c$ for some
value $c$. The true intercept is 0 for both the target and the external
populations, i.e. there is no actual bias in the intercept.
```{r}
betas <- numeric(d);
gammas_norm <- 0.5;
gammas <- gammas_norm * (2 * rbinom(d, 1, 0.5) - 1) / sqrt(d)
lp_tar <- drop(xtar %*% betas);
lp_ext <- drop(xext %*% (betas + gammas))
```

### Sample outcomes

We will use these linear predictors to generate binomial and time-to-event outcomes. 
Here are the binomial outcomes:

```{r}
ytar_bin <- rbinom(n_tar, size = 1, prob = plogis(lp_tar))
yext_bin <- rbinom(n_ext, size = 1, prob = plogis(lp_ext))
```

And here are the time-to-event outcomes with about 20\% censoring:

```{r}
set.seed(1);
time_ytar <- rexp(n_tar, exp(lp_tar))
time_yext <- rexp(n_ext, exp(lp_ext))
cens_ytar <- rexp(n_tar, 0.25 * mean(exp(lp_tar)))
cens_yext <- rexp(n_ext, 0.25 * mean(exp(lp_ext)))
ytar_te = Surv(pmin(time_ytar, cens_ytar), 1*(time_ytar < cens_ytar))
yext_te = Surv(pmin(time_yext, cens_yext), 1*(time_yext < cens_yext))
```


## binomial outcomes, `n_tar = 100`, `n_ext = 5000`

```{r}
n_tar_subsample = 100;
n_ext_subsample = 5000;
```

This is the DEGLR method with three values of $\lambda$: $\lambda \approx 0$,
$\lambda=0.01$, and $\lambda=1000$ The first corresponds to no pooling
across population and essentially separate models estimated for each population,
the second corresponds to partial pooling, and the last corresponds to full
pooling with $\gamma=0$.

```{r}
deglr_mod <- 
  deglr(xtar = xtar[1:n_tar_subsample,], 
        ytar = ytar_bin[1:n_tar_subsample], 
        xext = xext[1:n_ext_subsample,], 
        yext = yext_bin[1:n_ext_subsample], 
        family = "binomial", 
        return_what = c(1e-30,  1e3))
```

Both of the following should give equivalent results to DEGLR using $\lambda = 0$, 
i.e. no pooling across populations. 
```{r}
glm_nopool <- 
  glm(ytar_bin[1:n_tar_subsample] ~ xtar[1:n_tar_subsample,],
      family = "binomial") %>%
  coef() 
glmnet_nopool <- 
  glmnet(x = xtar[1:n_tar_subsample,], 
         y = ytar_bin[1:n_tar_subsample], 
         alpha = 0,  
         family = "binomial", 
         lambda = 0) %>%
  coef() %>% 
  drop()
```

This should give nearly equivalent results to $\lambda=1000$, i.e. full pooling across populations. 
```{r}
glm_pool <- 
  glm(c(ytar_bin[1:n_tar_subsample], 
        yext_bin[1:n_ext_subsample]) ~
        rbind(xtar[1:n_tar_subsample,], 
              xext[1:n_ext_subsample,]),
      family = "binomial") %>%
  coef()
```


```{r, echo = FALSE}
tibble(var_name = names(glmnet_nopool), 
       true_value = c(0, betas),
       glm_nopool = glm_nopool, 
       glmnet_nopool = glmnet_nopool, 
       deglr_nopool = deglr_mod$beta_hat[,1],
       deglr_pool = deglr_mod$beta_hat[,2],
       glm_pool = glm_pool) %>%
  kable(caption = glue("Comparison of estimates of $\\beta$ with a binomial outcome, {n_tar_subsample} samples
  from the target population, and {n_ext_subsample} samples from the external
  population. The 'nopool' methods 
  should be identical to each other (within convergence tolerance), and the 'pool' methods should be identical to
  each other."))
```



## binomial outcomes, `n_tar = 1000`, `n_ext = 1000`

```{r}
n_tar_subsample = 1000;
n_ext_subsample = 1000;
```

This is the DEGLR method with three values of $\lambda$: $\lambda \approx 0$,
$\lambda=0.01$, and $\lambda=1000$. The first corresponds to no pooling
across population and essentially separate models estimated for each population,
the second corresponds to partial pooling, and the last corresponds to full
pooling with $\gamma=0$.

```{r}
deglr_mod <- 
  deglr(xtar = xtar[1:n_tar_subsample,], 
        ytar = ytar_bin[1:n_tar_subsample], 
        xext = xext[1:n_ext_subsample,], 
        yext = yext_bin[1:n_ext_subsample], 
        family = "binomial", 
        return_what = c(1e-30,  1e3))
```

Both of the following should give equivalent results to DEGLR using $\lambda = 0$, 
i.e. no pooling across populations. 
```{r}
glm_nopool <- 
  glm(ytar_bin[1:n_tar_subsample] ~ xtar[1:n_tar_subsample,],
      family = "binomial") %>%
  coef() 
glmnet_nopool <- 
  glmnet(x = xtar[1:n_tar_subsample,], 
         y = ytar_bin[1:n_tar_subsample], 
         alpha = 0,  
         family = "binomial", 
         lambda = 0) %>%
  coef() %>% 
  drop()
```

This should give nearly equivalent results to $\lambda=1000$, i.e. full pooling across populations. 
```{r}
glm_pool <- 
  glm(c(ytar_bin[1:n_tar_subsample], 
        yext_bin[1:n_ext_subsample]) ~
        rbind(xtar[1:n_tar_subsample,], 
              xext[1:n_ext_subsample,]),
      family = "binomial") %>%
  coef()
```


```{r, echo = FALSE}
tibble(var_name = names(glmnet_nopool), 
       true_value = c(0, betas),
       glm_nopool = glm_nopool, 
       glmnet_nopool = glmnet_nopool, 
       deglr_nopool = deglr_mod$beta_hat[,1],
       deglr_pool = deglr_mod$beta_hat[,2],
       glm_pool = glm_pool) %>%
  kable(caption = glue("Comparison of estimates of $\\beta$ with a binomial outcome, {n_tar_subsample} samples
  from the target population, and {n_ext_subsample} samples from the external
  population. The 'nopool' methods 
  should be identical to each other (within convergence tolerance), and the 'pool' methods should be identical to
  each other."))
```

## time-to-event outcomes,  `n_tar = 100`, `n_ext = 5000`

Repeat the same exercise for the time-to-event outcomes. One subtly here is how
to handle the baseline hazard. The two most obvious options are (i) always fit a
stratified Cox model to estimate completely separate baseline hazards or (ii)
fit a proportionality bias term for the baseline hazard in the external data,
e.g. insert a constant column into the external predictors and estimate the
corresponding bias term for that predictor.

Both have potential downsides. Option (i) will never fully pool the data: even
when $\lambda = \inf$, separate baseline hazards will be estimated. Option (ii)
cannot fit separate models: even when $\lambda = 0$, it is assumed that the
baseline hazards are proportional to eachother at every time $t$, so that some
information is shared between the populations. We choose option (i).

```{r}
n_tar_subsample = 100;
n_ext_subsample = 5000;
```

This is the DEGLR method with three values of $\lambda$: $\lambda \approx 0$,
$\lambda=0.01$, and $\lambda=1000$ The first corresponds to no pooling
across population and essentially separate models estimated for each population,
the second corresponds to partial pooling, and the last corresponds to full
pooling with $\gamma=0$.

```{r}
deglr_mod <- 
  deglr(xtar = xtar[1:n_tar_subsample,], 
        ytar = ytar_te[1:n_tar_subsample], 
        xext = xext[1:n_ext_subsample,], 
        yext = yext_te[1:n_ext_subsample], 
        family = "cox", 
        return_what = c(1e-30,  1e3))
```

Both of the following should give equivalent results to DEGLR using $\lambda = 0$, 
i.e. no pooling across populations. 
```{r}
coxph_nopool <- 
  coxph(ytar_te[1:n_tar_subsample] ~ xtar[1:n_tar_subsample,]) %>%
  coef()
glmnet_nopool <- 
  glmnet(x = xtar[1:n_tar_subsample,], 
         y = ytar_te[1:n_tar_subsample], 
         alpha = 0,  
         family = "cox", 
         lambda = 0) %>% 
  coef() %>% 
  drop()
```

This should give nearly equivalent results to $\lambda=1000$, i.e. full pooling
across populations (note however that we are estimating separate baseline
hazards using the `strata` argument).

```{r}
coxph_pool <- 
  coxph(c(ytar_te[1:n_tar_subsample], 
          yext_te[1:n_ext_subsample]) ~ 
          rbind(xtar[1:n_tar_subsample,], 
                xext[1:n_ext_subsample,]) + 
          strata(c(rep(1, n_tar_subsample), rep(2, n_ext_subsample)))) %>% 
  coef()
```


```{r, echo = FALSE}
tibble(var_name = names(glmnet_nopool), 
       true_value = betas,
       coxph_nopool = coxph_nopool, 
       glmnet_nopool = glmnet_nopool, 
       deglr_nopool = deglr_mod$beta_hat[,1],
       deglr_pool = deglr_mod$beta_hat[,2],
       coxph_pool = coxph_pool) %>%
  kable(caption = glue("Comparison of estimates of $\\beta$ with a time-to-event outcome, {n_tar_subsample} samples
  from the target population, and {n_ext_subsample} samples from the external
  population. The 'nopool' methods 
  should be identical to each other (within convergence tolerance), the 'pool' methods should be identical to
  each other."))
```


## time-to-event outcomes,  `n_tar = 1000`, `n_ext = 1000`

```{r}
n_tar_subsample = 1000;
n_ext_subsample = 1000;
```

This is the DEGLR method with three values of $\lambda$: $\lambda \approx 0$,
$\lambda=0.01$, and $\lambda=1000$ The first corresponds to no pooling
across population and essentially separate models estimated for each population,
the second corresponds to partial pooling, and the last corresponds to full
pooling with $\gamma=0$.

```{r}
deglr_mod <- 
  deglr(xtar = xtar[1:n_tar_subsample,], 
        ytar = ytar_te[1:n_tar_subsample], 
        xext = xext[1:n_ext_subsample,], 
        yext = yext_te[1:n_ext_subsample], 
        family = "cox", 
        return_what = c(1e-30,  1e3))
```

Both of the following should give equivalent results to DEGLR using $\lambda = 0$, 
i.e. no pooling across populations. 
```{r}
coxph_nopool <- 
  coxph(ytar_te[1:n_tar_subsample] ~ xtar[1:n_tar_subsample,]) %>%
  coef()
glmnet_nopool <- 
  glmnet(x = xtar[1:n_tar_subsample,], 
         y = ytar_te[1:n_tar_subsample], 
         alpha = 0,  
         family = "cox", 
         lambda = 0) %>% 
  coef() %>% 
  drop()
```

This should give nearly equivalent results to $\lambda=1000$, i.e. full pooling
across populations (note however that we are estimating separate baseline
hazards using the `strata` argument).

```{r}
coxph_pool <- 
  coxph(c(ytar_te[1:n_tar_subsample], 
          yext_te[1:n_ext_subsample]) ~ 
          rbind(xtar[1:n_tar_subsample,], 
                xext[1:n_ext_subsample,]) + 
          strata(c(rep(1, n_tar_subsample), rep(2, n_ext_subsample)))) %>% 
  coef()
```

```{r, echo = FALSE}
tibble(var_name = names(glmnet_nopool), 
       true_value = betas,
       coxph_nopool = coxph_nopool, 
       glmnet_nopool = glmnet_nopool, 
       deglr_nopool = deglr_mod$beta_hat[,1],
       deglr_pool = deglr_mod$beta_hat[,2],
       coxph_pool = coxph_pool) %>%
  kable(caption = glue("Comparison of estimates of $\\beta$ with a time-to-event outcome, {n_tar_subsample} samples
  from the target population, and {n_ext_subsample} samples from the external
  population. The 'nopool' methods 
  should be identical to each other (within convergence tolerance), and the 'pool' methods should be identical to
  each other."))
```


## Tuning parameter selection by cross-validation

We provide a function `cv_deglr` that allows for selecting the among of pooling
via cross-validation. We demonstrate here using the binomial-outcome data
generated above. In the first example, we consider 100 observations from the
target population and 5000 from the external. Intuitively, we would expect a
considerable amount of pooling due to the small sample size in the target
population and large number of predictors. The `ncvreps` argument allows for
creating multiple partitions, to smooth over noise arising from any single one:

```{r cv1, cache = TRUE}

n_tar_subsample = 100;
n_ext_subsample = 5000;

model_select <- cv_deglr(xtar = xtar[1:n_tar_subsample,], 
                         ytar = ytar_bin[1:n_tar_subsample], 
                         xext = xext[1:n_ext_subsample,], 
                         yext = yext_bin[1:n_ext_subsample], 
                         family = "binomial", 
                         alpha = 0.0,
                         nfolds = 5, 
                         ncvreps = 5)
plot(log(model_select$lambda_seq), model_select$neg_log_likelihood)
abline(v = log(model_select$lambda_opt))
```

We can compare the RMSE in estimation against a model that ignores the external
data (remember that the true value of $\beta$ is zero, so the RMSE is just the
rooted average of the squared coefficient estimates). 


```{r}
# Pooled model:
sqrt(mean(model_select$beta_hat^2))
# Base model
sqrt(mean(coef(glm(ytar_bin[1:n_tar_subsample] ~ xtar[1:n_tar_subsample,], family = "binomial"))^2))
```

Now, consider 1000 observations from each. We would expect less pooling as there
is more information in the target sample. 

```{r cv2, cache = TRUE}

n_tar_subsample = 1000;
n_ext_subsample = 1000;

model_select <- cv_deglr(xtar = xtar[1:n_tar_subsample,], 
                         ytar = ytar_bin[1:n_tar_subsample], 
                         xext = xext[1:n_ext_subsample,], 
                         yext = yext_bin[1:n_ext_subsample], 
                         family = "binomial", 
                         alpha = 0.0,
                         nfolds = 5, 
                         ncvreps = 5)
plot(log(model_select$lambda_seq), model_select$neg_log_likelihood)
abline(v = log(model_select$lambda_opt))
```

We can compare the RMSE in estimation against a model that ignores the external
data (remember that the true value of $\beta$ is zero, so the RMSE is just the
rooted average of the squared coefficient estimates). 


```{r}
# Pooled model:
sqrt(mean(model_select$beta_hat^2))
# Base model
sqrt(mean(coef(glm(ytar_bin[1:n_tar_subsample] ~ xtar[1:n_tar_subsample,], family = "binomial"))^2))
```


## Summary

This simple simulation study empirically shows that the deglr algorithm behaves
as expected in the simple situations where we want to completely pool the two
populations or estimate completely separate associations.

As we note above, the fully pooled Cox model does not actually fully pool
the data: separate baseline hazards are always estimated. 

```{r, echo = FALSE}
if(0) {

  
  foo$beta_hat
  
  sqrt(mean(coef(glmnet(x = xtar[1:n_tar_subsample,], y = ytar_bin[1:n_tar_subsample], alpha = 0,  family = "binomial", lambda = 0))^2))
  foo$lambda_opt
  
  
  foo2 <- glmtrans(target = list(x = xtar[1:n_tar_subsample,], 
                                 y = ytar_bin[1:n_tar_subsample]), 
                   source = list(list(x = xext[1:50,], 
                                      y = yext_bin[1:50]),
                                 list(x = xext[100:132,], 
                                      y = yext_bin[100:132])), 
                   family = "binomial",
                   transfer.source.id = "all",
                   alpha = 0.0)
  
}

if(0) {
  
  lp_aug = c(numeric(n_tar_subsample),(cbind(1, xext[1:n_ext_subsample,]) %*% foo$gamma_hat[,1]))
  if(family == "binomial") {
    glm(c(ytar_bin, yext_bin) ~ rbind(xtar, xext) + offset(lp_aug), family = "binomial") %>% coef() %>% print()
  } else if (family == "cox") {
    coxph(c(ytar_te[1:n_tar_subsample,], 
            yext_te[1:n_ext_subsample,]) ~ rbind(xtar[1:n_tar_subsample,], 
                                                 xext[1:n_ext_subsample,]) + offset(lp_aug)) %>% coef() %>% print()
  }
  foo$beta_hat
}
```




